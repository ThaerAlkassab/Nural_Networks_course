{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cats vs Dogs classification with a small dataset\n",
    "\n",
    "We are going to use the Kaggle competition [Cats vs Dogs](https://www.kaggle.com/c/dogs-vs-cats/data) dataset with over 25k labelled images in the train set. We are going to use only a small part of the dataset for our purposes:\n",
    "\n",
    "- 2k images for training (1k cats + 1k dogs)\n",
    "- 2k images for validation (model selection)\n",
    "- 2k images for testing\n",
    "\n",
    "The prepared dataset temporarily is available [here](http://rs1.sze.hu/~katihi/titkos/cats_vs_dogs.zip).\n",
    "\n",
    "See a related article: Elson, J., Douceur, J. R., Howell, J., & Saul, J. (2007). Asirra: a CAPTCHA that exploits interest-aligned manual image categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import he_normal\n",
    "from keras.regularizers import L2\n",
    "from keras.optimizers import SGD, Adam, RMSprop, AdamW\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from IPython.display import Image\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Flatten, Activation, AveragePooling2D, Conv2D, Add \n",
    "from keras.layers import MaxPooling2D, Reshape, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.utils import to_categorical, plot_model, set_random_seed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    import requests\n",
    "    import zipfile\n",
    "    import io\n",
    "    \n",
    "    url = \"http://rs1.sze.hu/~katihi/titkos/cats_vs_dogs.zip\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
    "            zip_ref.extractall(\".\") \n",
    "        print(\"File downloaded and extracted successfully!\")\n",
    "    else:\n",
    "        print(f\"Failed to download file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build some simple models for baseline\n",
    "\n",
    "Since we are working with such a small number of images, we definitely need the ImageDataGenerator modifications for the images.\n",
    "\n",
    "With the `flow_from_directory` function we can specify:\n",
    "- the directory we want to read the data from\n",
    "- `target_size`: the shape we want to resize to\n",
    "- `batch_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_flows(width, height, batch_size=32):\n",
    "    #VGG input shape is: 224*224, InceptionResNetV2 input shape is 299*299\n",
    "\n",
    "    train_dir = \"cats_vs_dogs/train/\"\n",
    "    val_dir =   \"cats_vs_dogs/validation/\"\n",
    "    test_dir =  \"cats_vs_dogs/test/\"\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                   width_shift_range=0.1,\n",
    "                   height_shift_range=0.1,\n",
    "                   horizontal_flip=True)\n",
    "\n",
    "    \n",
    "    return train_flow, val_flow, test_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, batch_size = 64, 64, 32\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN with MaxPooling/GlobalAveragePooling\n",
    "\n",
    "Let's build a very simple CNN model for binary classification (we have two classes) with\n",
    "\n",
    "- 2 consecutive Conv2D layers\n",
    "- (1 MaxPooling layer + a flattening layer) or (1 GlobalAveragePooling)\n",
    "- 2 fully connected Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce model complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "We are going to use an already pre-trained model with its weights and just change the final dense/prediction layers.\n",
    "Available pre-trained models in Keras can be found [here](https://keras.io/api/applications/)\n",
    "\n",
    "These models were trained on millions of images and 1000 classes on the ImageNet challenge dataset. Those classes contain several cat and dog breeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - We have to change the prediction layer to two classes\n",
    " - We need to freeze most of the layers we don't want re-train the whole model, and only unfreeze the final few layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We freeze the VGG layers (set their weights non-trainable)\n",
    "- cut the prediction layer\n",
    "- replace it with our Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing input\n",
    "\n",
    "- We should use the same preprocessing as it was in the original training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "def create_flows_with_preprocess(width, height, batch_size=32):\n",
    "    #VGG input shape is: 224*224, InceptionResNetV2 input shape is 299*299\n",
    "\n",
    "\n",
    "    return train_flow, val_flow, test_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionResNetV2\n",
    "\n",
    "Let's try to fine-tune an even better and deeper model, the [`InceptionResNetV2`](https://arxiv.org/abs/1602.07261)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "\n",
    "inception = InceptionResNetV2(include_top=False, input_shape=(299, 299, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at the model's predictions and its mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def predict(filename):\n",
    "    img = load_img(filename, target_size=(299, 299, 3))\n",
    "    img = img_to_array(img).reshape(1, 299, 299, 3) / 255\n",
    "\n",
    "    return model.predict(img)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dogs that were incorrectly identified as cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(2000, 3000):\n",
    "    filename = f\"cats_vs_dogs/test/dog/dog.{idx}.jpg\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cats that were incorrectly identified as dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(2000, 3000):\n",
    "    filename = f\"cats_vs_dogs/test/cat/cat.{idx}.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
